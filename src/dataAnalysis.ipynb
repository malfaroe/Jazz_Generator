{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import copy\n",
    "import music21 as m21\n",
    "from music21 import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pickle as pkl\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import glob \n",
    "from pathlib import Path\n",
    "\n",
    "import configure\n",
    "\n",
    "def load_songs(data_path):\n",
    "    \"\"\"loads all the songs in the data folder and \n",
    "    converts them into a m21 stream object\n",
    "    args: data path\n",
    "    returns: a list of all the converted songs\n",
    "    Important concept: parsing is the process of recognizing and identifying the components of\n",
    "    a particular input\"\"\"\n",
    "    songs = []\n",
    "    for path, subdirs, files in os.walk(data_path):\n",
    "        for i, file in enumerate(files):\n",
    "            try:\n",
    "                if file[-3:] == \"mid\" or file[-4:] == \"midi\":\n",
    "                    song = m21.converter.parse(os.path.join(path, file)) #parsing...crea un objeto stream.Score\n",
    "                    songs.append(song)\n",
    "            except:\n",
    "                print(\"Failed loading the: {} song\".format(i))\n",
    "    \n",
    "    print(\"{} songs successfully loaded and converted to m21 stream objects\".format(len(songs)))\n",
    "\n",
    "    return songs\n",
    "\n",
    "\n",
    "def has_acceptable_duration(song, acceptable_durations):\n",
    "    \"\"\"Returns a boolean for checking if the song copmponents has\n",
    "    all its elements of the acceptable durations\n",
    "    args:\n",
    "    song: m21 stream\n",
    "    acceptable_durations: list cointaining the acceptable durations\n",
    "    Al decir for note in song.flat.notesAndRests repasamos toda la cancion\"\"\"\n",
    "    #load the song: reads it as argument\n",
    "\n",
    "\n",
    "    #check for each component if has acceptable durations\n",
    "    for note in song.flat.notesAndRests:\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "    #returns True/False\n",
    "    return True\n",
    "    \n",
    "def songs_has_no_chords(song):\n",
    "    \"\"\"Returns a boolean True indicating if song has no chords\"\"\"\n",
    "    for element in song.flat.notesAndRests:\n",
    "        if isinstance(element, m21.chord.Chord):\n",
    "            return False\n",
    "    #Returns False by default\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_durations(song, acceptable_durations):\n",
    "    \"\"\"Returns a boolean for checking if the song copmponents has\n",
    "    all its elements of the acceptable durations\n",
    "    args:\n",
    "    song: m21 stream\n",
    "    acceptable_durations: list cointaining the acceptable durations\n",
    "    \"\"\"\n",
    "    #load the song: reads it as argument\n",
    "\n",
    "\n",
    "    #check for each component if has acceptable durations\n",
    "    durations = []\n",
    "    for note in song.flat.notesAndRests:\n",
    "        durations.append(note.duration.quarterLength) \n",
    "            \n",
    "    return durations\n",
    "\n",
    "def aproximate_duration(duration, acceptable_durations):\n",
    "    \"\"\"Aproximates the non-accep´table durations depending on\n",
    "    the duration of the element:\n",
    "    if < 0.25: round to 0.25\n",
    "    if > 0.25 and is multiple of 0.25 ---> round to the highest acceptable duration\n",
    "    if > 0.25 and is not multiple of 0.25 ---> round to the nearest multiple inside the list\"\"\"\n",
    "\n",
    "    #if number less than 0.25 ---> aproximate to 0.25\n",
    "    if duration < 0.25:\n",
    "        return 0.25\n",
    "\n",
    "    else:\n",
    "        #If is multiple of 0.25 but higher than the highest in duration list reduce to the highest\n",
    "        if duration % 0.25 == 0:\n",
    "            return acceptable_durations[-1]\n",
    "            \n",
    "    \n",
    "        else: #Round up to the nearest multiple of 0.25\n",
    "            return 0.25 * round(duration / 0.25)\n",
    "\n",
    "def repair_durations(song, acceptable_durations):\n",
    "    for note in song.flat.notesAndRests:\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            note.duration.quarterLength  = aproximate_duration(note.duration.quarterLength, acceptable_durations)\n",
    "    return song\n",
    "    \n",
    "            \n",
    "\n",
    "def transpose_song(song):\n",
    "    \"\"\"Transpose the song to Cmajor/Aminor\n",
    "    arg: song as ms21 object\n",
    "    return: song transposed\"\"\"\n",
    "    #Get the original key of the song\n",
    "    parts = song.getElementsByClass(m21.stream.Part) #Extrae todas las partes de la canción (violin, viola, etc)\n",
    "    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure) #Extrae los elementos de la parte0 como referencia\n",
    "    \n",
    "    try: \n",
    "        key = measures_part0[0][4] ##tomo la primera parte de measures0 y extraigo de esa lista el elemento 4 que es key\n",
    "\n",
    "    except:\n",
    "        key = song.analyze(\"key\") #si no resulta de esa forma que intente este metodo\n",
    "\n",
    "    #If we cant get the key by the previous method because is not in the song, estimate it\n",
    "    if not isinstance(key, m21.key.Key): #if the song doesnt hace any key stored\n",
    "        key = song.analyze(\"key\") #estimate it...\n",
    "\n",
    "    #Calculate the interval or distance to transpose\n",
    "    #si esta en tono mayor calcula intervalo con A minor\n",
    "    #print(\"The song is originilally in the key of {}\".format(key))\n",
    "    if key.mode == \"minor\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\")) #key.tonic da el tono en que está\n",
    "\n",
    "    elif key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\")) #key.tonic da el tono en que está\n",
    "\n",
    "    #Transpose the song\n",
    "\n",
    "    transposed_song = song.transpose(interval)\n",
    "\n",
    "    #print(\"The song has been transposed to the key of {}\".format(transposed_song.analyze(\"key\")))\n",
    "\n",
    "    return transposed_song\n",
    "\n",
    "\n",
    "def encode_song(song, time_step = 0.25):\n",
    "    \"\"\"method for converting a stream object into a time series sequence,\n",
    "    considering a time step of 0.25 (1 semicorchea). Le time series avanzara a\n",
    "    un paso de 1 semicorchea\n",
    "    returns: a list with the form [60,_,_, r, 67,_, 74, _, _, 34]\"\"\"\n",
    "    #song = song.chordify() ##testing\n",
    "    encoded_song = []\n",
    "    chord_count = 0\n",
    "    for event in song.flat.notesAndRests: #crea una lista de todos los elementos de la cancion (notas, rests)\n",
    "        #si event es una nota guarda la nota\n",
    "        if isinstance(event, m21.note.Note):\n",
    "            symbol = event.pitch.midi #le asigna su equvalente de la nota en valor midi\n",
    "        #Si es un acorde...\n",
    "        elif isinstance(event, m21.chord.Chord):\n",
    "           #testing what happens if not considering he chords\n",
    "            current_chord= \".\".join(str(n.pitch.midi) for n in event)\n",
    "            symbol = current_chord\n",
    "\n",
    "            continue\n",
    "        elif isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "    \n",
    "        #Calcula el nro de time_steps que dura el evento:\n",
    "        nr_time_steps = int(event.duration.quarterLength / time_step)\n",
    "\n",
    "        #Ahora voy guardando en encoded song considerando que si estoy al principio (Nr_time_step = 0)\n",
    "        #append la nota/rest y para el resto \"_\"\n",
    "\n",
    "        for step in range(nr_time_steps):\n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")\n",
    "\n",
    "    #Convierto con map todos los caracteres de encoded_song a str\n",
    "    #y luego los uno separados por un \" \"\n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "    return encoded_song\n",
    "\n",
    "\n",
    "\n",
    "#Saving all the encoded songs in one file\n",
    "SEQUENCE_LENGTH = 64 #nr of repetitions of \"/\"\n",
    "SINGLE_FILE_PATH = \"single_dataset\" #name of the single file to be created \n",
    "\n",
    "def load(dataset_path):\n",
    "    \"\"\"Utility for reading individual songs from a directory\"\"\"\n",
    "    with open(dataset_path,\"r\") as fp:\n",
    "        song = fp.read()\n",
    "        return song\n",
    "\n",
    "def create_single_file_dataset(dataset_path, single_file_path, sequence_length):\n",
    "    \"\"\"Se crea un gran archivo tipo strong donde se almacenan todas las canciones del dataset,\n",
    "    separadas por un delimitador /\n",
    "    Delimitador: simbolo \"/ \" repetido 64 veces, ya que asi las leen las LSTM\n",
    "    args:\n",
    "    dataset_path: path of the directory of individual songs (the already encoded songs)\n",
    "    single_file_path: where the single file to bre created will be saved/name of the single file\n",
    "    sequence_length: to be used for indicating the beginning of a new song\"\"\"\n",
    "    songs = \" \"\n",
    "    new_song_delimiter = \"/ \" * sequence_length #separador de canciones\n",
    "    print(\"Creating single file sequence...\")\n",
    "    #Paso por todos los archivos del directorio dataset_path, load song, put delimiters \n",
    "    for path, _, files,  in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file) #ubicacion exacta de la cancion\n",
    "            song = load(file_path) #metodo para load la cancion\n",
    "            songs = songs + song + \" \" + new_song_delimiter\n",
    "\n",
    "    songs = songs[:-1] #recorto espacio que quedaria en el deliminador de la ultima cancion\n",
    "\n",
    "    #Save the songs\n",
    "    with open(single_file_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "    print(\"Single sequence file created...\")\n",
    "    return songs\n",
    "\n",
    "\n",
    "def preprocess(dataset_path):\n",
    "    \"\"\"sequence of reading, processing the midi files into encoded songs and\n",
    "    saving them into a new SAVE_DIR\n",
    "    args:\n",
    "    dataset_path: original midi data folder\n",
    "    Steps:\n",
    "    #read the midi songs from the data_path and convert them into stream m21 (saved in a list)\n",
    "    #Correct each song with acceptable durations criteria\n",
    "    #Transpose each song to Cmajor/Aminor key\n",
    "    #encode each song into its equivalent midi numbers and rest symbols\n",
    "    #Save all songs in SAVE_DIR\n",
    "    \n",
    "    \"\"\"\n",
    "    #Empty the save_dir directory before starts...\n",
    "    [f.unlink() for f in Path(configure.SAVE_DIR).glob(\"*\") if f.is_file()] \n",
    "\n",
    "    #Load and convert songs to m21 streams...\n",
    "    print(\"Loading songs...\")\n",
    "    initial_songs = load_songs(dataset_path)\n",
    "    \n",
    "    #Correct each song with acceptable durations criteria\n",
    "    songs = []\n",
    "    for song in initial_songs:\n",
    "        song = repair_durations(song, configure.ACCEPTABLE_DURATIONS)\n",
    "        songs.append(song)\n",
    "    print(\"{} songs loaded and with their duration corrected\".format(len(songs)))\n",
    "\n",
    "    #Transpose and encode each song...\n",
    "    print(\"Transposing and encoding  songs...\")\n",
    "    out_songs = 0\n",
    "    enc_songs = 0\n",
    "    for i, song in enumerate(songs):\n",
    "        song = transpose_song(song)\n",
    "        encoded_song = encode_song(song, time_step= 0.25)\n",
    "        enc_songs += 1\n",
    "        #Save sons as text file in SAVE_DIR \n",
    "        save_path = os.path.join(configure.SAVE_DIR, str(i)) #saves each song with a number\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "    print(\"Number of encoded songs saved in Save_dir:\", enc_songs)\n",
    "\n",
    "#Create a dictionary for mapping the symbols\n",
    "\n",
    "def create_mapping(songs, mapping_json_name):\n",
    "    \"\"\"Creates a dictionary of each symbol: integer\n",
    "    args:\n",
    "    songs: single file with all songs encoded together\n",
    "    mapping_json_name: name that will have the dictionary\n",
    "    \n",
    "    returns:\n",
    "    Saves the vocabulary as mappins_json_name json file\n",
    "    Vocabulary_elements (list): list of all the unique elements\"\"\"\n",
    "    mappings = {}\n",
    "    songs_elements = songs.split() #separa todos los elementos del archivo songs\n",
    "    vocabulary_elements = list(set(songs_elements)) #lista de los elementos unicos\n",
    "    for i, symbol in enumerate(vocabulary_elements):\n",
    "        mappings[symbol] = i\n",
    "\n",
    "    with open(mapping_json_name, \"w\") as fp:\n",
    "        json.dump(mappings, fp, indent = 4)\n",
    "    #print(\"Vocabulary:\", vocabulary)\n",
    "    print(\"VOCAB_LENGTH:\", len(vocabulary_elements))\n",
    "    print(\"Mapping created...\")\n",
    "    return vocabulary_elements\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Convert  the single file symbols into integers using the mapping\n",
    "def convert_into_integers(single_file):\n",
    "    \"\"\"Takes the single file and coverts its symbols into integers using\n",
    "    the mapping created\"\"\"\n",
    "    int_single_file =[] #vaciamos el mapeo a una lista\n",
    "    #Open the json mapping file\n",
    "    with open (configure.MAPPING_JSON_NAME, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "    \n",
    "    #Split of elements in single file\n",
    "    single_file = single_file.split()\n",
    "\n",
    "    #Map songs into integers\n",
    "    for symbol in single_file:\n",
    "        int_single_file.append(mappings[symbol])\n",
    "    print(\"Single file converted to integers using the mapping\")\n",
    "    return int_single_file\n",
    "\n",
    "#Create training sequences \n",
    "#Generating training sequences...\n",
    "#las LSTM se estructuran tomando una secuencia de notas y prediciendo cual es la proxima\n",
    "#Por ser supervisado, se le da una secuencia y se le muestra un target; asi se va entrenando\n",
    "#Por ello tomaremos una secuencia de 64 time_steps (que equivalen a 4 compases de 4/4) como sample\n",
    "#y como target le mostramos la siguiente nota o figura. Recuerda que cada time_step es una semicorchea\n",
    "#Para ello las secuencias se construyen considerando que se trata de un time series, mviendose\n",
    "#con un window hacia adelante\n",
    "#En este caso, dado que tenemos un sequence length de 64 timesteps, si hay 100 symbols en total\n",
    "#y nos movemos de a uno en la ventana, tendriamos un total de secuencias de 100 - 64\n",
    "\n",
    "def generate_training_sequences(sequence_length):\n",
    "    \"\"\"Takes the integer converted sequence and creates sequences of examples and targets:\n",
    "    examples: 64 elements\n",
    "    target: the following element\n",
    "    output: inputs and targets\n",
    "    input vector shape: nr_of_songs x sequence_length x nr_of_symbols(or features)\"\"\"\n",
    "    #load the songs and map them to int\n",
    "    songs = load(SINGLE_FILE_PATH)\n",
    "    int_song = convert_into_integers(songs)\n",
    "\n",
    "    inputs = [] #to save the examples/sequences\n",
    "    targets = []\n",
    "    number_of_sequences = len(int_song) - sequence_length # cantidad de secuencias que se van a generar\n",
    "\n",
    "    for i in range(number_of_sequences):\n",
    "        inputs.append(int_song[i: i + sequence_length])\n",
    "        targets.append(int_song[i + sequence_length]) #la siguiente nota/rest\n",
    "    \n",
    "    #Convert to one-hot encoding for creating the input vectors\n",
    "    vocab_size = len(set(int_song)) #unique elements\n",
    "    print(\"Vocab size:\", vocab_size)\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes = vocab_size)\n",
    "    #Convert targets to array\n",
    "    targets = np.array(targets)\n",
    "    print(\"Training data successfully generated\")\n",
    "    return inputs, targets, vocab_size\n",
    "\n",
    "\n",
    "###PP\n",
    "\n",
    "\n",
    "def create_data_sequences(mapped_song):\n",
    "    \"\"\" Creates the training data taking the sequence\n",
    "    and creating sequences of 100 elements as input\n",
    "    and the next element as the targets, moving in a window\n",
    "    of 1 step. Also shapes the input data to the format\n",
    "    demanded by the LSTM: (len_dataset, SEQUENCE_LENGTH,1)\n",
    "    args: \n",
    "    inputs:mapped song: list of elements mapped into integers\n",
    "    returns: \n",
    "    - input data before scaling and reshaping (list)\n",
    "    - input_data_final: scaled and reshaped data ready for training (array)\n",
    "    - target data\"\"\"\n",
    "\n",
    "    SEQUENCE_LENGTH = 100 #largo de cada secuencia\n",
    "    NUM_SEQUENCES = len(mapped_song) - SEQUENCE_LENGTH #total secuencias\n",
    "\n",
    "    input_data = []\n",
    "    targets = []\n",
    "    #Creating the sequences...\n",
    "    for i in range(0, NUM_SEQUENCES, 1):\n",
    "        input_data.append(mapped_song[i: i + SEQUENCE_LENGTH])\n",
    "        targets.append(mapped_song[i + SEQUENCE_LENGTH])\n",
    "\n",
    "    print(\"Training data created\")\n",
    "    print(\"Dataset size:\", len(input_data))\n",
    "    #input_data = np.array(input_data) #input data before scaling\n",
    "    targets = np.array(targets)\n",
    "    #Normalize input data\n",
    "    scaler = MinMaxScaler()\n",
    "    input_data_scaled = scaler.fit_transform(input_data)\n",
    "    \n",
    "    #Reshape the input into a format compatible with LSTM layers...\n",
    "    input_data_final = np.reshape(input_data_scaled, ((len(input_data_scaled), SEQUENCE_LENGTH,1)))\n",
    "    \n",
    "    #input_data = input_data / len(set(mapped_song))\n",
    "\n",
    "    #One hot encode the output\n",
    "    targets = to_categorical(targets)\n",
    "\n",
    "    return input_data , input_data_final, targets\n",
    "\n",
    "#CHECKING AND LEARNING ABOUT DATA\n",
    "\n",
    "###pp\n",
    "def mapping_data(song):\n",
    "    \"\"\"Mapping all the elements of song to integers and\n",
    "    saves the mappings dictionary\n",
    "    arg:\n",
    "    input (list): song encoded with the initial form (B4,r, F)\n",
    "    output (list): mapped_song, list with song mapped to integers\"\"\"\n",
    "    #obtener vocabulario los elementos unicos\n",
    "    vocabulary = list(set(song))\n",
    "    vocab_length = len(vocabulary)\n",
    "    print(\"vocab length:\", vocab_length)\n",
    "    #crear un diccionario {elemento: numero}\n",
    "    mapping_dict = {}\n",
    "    for i, element in enumerate(vocabulary):\n",
    "        mapping_dict[element] = i\n",
    "\n",
    "    #Save mapping dict\n",
    "    with open(\"mapping_modular.json\", \"w\") as fp:\n",
    "        json.dump(mapping_dict, fp, indent = 4)\n",
    "\n",
    "    #mapear la cancion\n",
    "    mapped_song = []\n",
    "    for element in song:\n",
    "        mapped_song.append(mapping_dict[element])\n",
    "    #return cancion mapeada\n",
    "    return mapped_song, vocab_length, vocabulary\n",
    "  \n",
    "###ppp\n",
    "def create_data_sequences(mapped_song):\n",
    "    \"\"\" Creates the training data taking the sequence\n",
    "    and creating sequences of 100 elements as input\n",
    "    and the next element as the targets, moving in a window\n",
    "    of 1 step. Also shapes the input data to the format\n",
    "    demanded by the LSTM: (len_dataset, SEQUENCE_LENGTH,1)\n",
    "    args: \n",
    "    inputs:mapped song: list of elements mapped into integers\n",
    "    returns: \n",
    "    - input data before scaling and reshaping (list)\n",
    "    - input_data_final: scaled and reshaped data ready for training (array)\n",
    "    - target data\"\"\"\n",
    "\n",
    "    SEQUENCE_LENGTH = 100 #largo de cada secuencia\n",
    "    NUM_SEQUENCES = len(mapped_song) - SEQUENCE_LENGTH #total secuencias\n",
    "\n",
    "    input_data = []\n",
    "    targets = []\n",
    "    #Creating the sequences...\n",
    "    for i in range(0, NUM_SEQUENCES, 1):\n",
    "        input_data.append(mapped_song[i: i + SEQUENCE_LENGTH])\n",
    "        targets.append(mapped_song[i + SEQUENCE_LENGTH])\n",
    "\n",
    "    print(\"Training data created\")\n",
    "    print(\"Dataset size:\", len(input_data))\n",
    "    #input_data = np.array(input_data) #input data before scaling\n",
    "    targets = np.array(targets)\n",
    "    #Normalize input data\n",
    "    scaler = MinMaxScaler()\n",
    "    input_data_scaled = scaler.fit_transform(input_data)\n",
    "    \n",
    "    #Reshape the input into a format compatible with LSTM layers...\n",
    "    input_data_final = np.reshape(input_data_scaled, ((len(input_data_scaled), SEQUENCE_LENGTH,1)))\n",
    "    \n",
    "    #input_data = input_data / len(set(mapped_song))\n",
    "\n",
    "    #One hot encode the output\n",
    "    targets = to_categorical(targets)\n",
    "\n",
    "    return input_data , input_data_final, targets\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading songs...\n",
      "Failed loading the: 80 song\n",
      "Failed loading the: 122 song\n",
      "Failed loading the: 160 song\n",
      "464 songs successfully loaded and converted to m21 stream objects\n",
      "464 songs loaded and with their duration corrected\n",
      "Transposing and encoding  songs...\n",
      "Number of encoded songs saved in Save_dir: 464\n",
      "Creating the single file...\n",
      "Creating single file sequence...\n",
      "Single sequence file created...\n",
      "Single file created\n",
      "Mapping...\n",
      "VOCAB_LENGTH: 78\n",
      "Mapping created...\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #Load, correct duration, transpose, encode and save to a save_dir...\n",
    "    preprocess(configure.DATA_PATH)\n",
    "\n",
    "    #Create a single string of all the songs delimited by ///\n",
    "    print(\"Creating the single file...\")\n",
    "    single_file_song =  create_single_file_dataset(configure.SAVE_DIR,configure.SINGLE_FILE_PATH, configure.SEQUENCE_LENGTH)\n",
    "    print(\"Single file created\")\n",
    "    #Mapping all the symbols into a integer vocabulary\n",
    "    print(\"Mapping...\")\n",
    "    # mapped_song, vocab_length = mapping_data(single_file_song)\n",
    "    create_mapping(single_file_song, configure.MAPPING_JSON_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 14\n"
     ]
    }
   ],
   "source": [
    "mapped_song, vocab_length, vocabulary = mapping_data(single_file_song)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_LENGTH: 78\n",
      "Mapping created...\n",
      "Single file converted to integers using the mapping\n",
      "Training data created\n",
      "Dataset size: 839870\n"
     ]
    }
   ],
   "source": [
    "#Creates the vocabulary in a json mapping file\n",
    "vocabulary_elements = create_mapping(single_file_song, configure.MAPPING_JSON_NAME)\n",
    "#Mappinbg the single file into integers using mappings vocabulary\n",
    "single_file_integer = convert_into_integers(single_file_song)\n",
    "#Generate training sequences\n",
    "X, X_f, y = create_data_sequences(single_file_integer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"training_data.pkl\", \"wb\") as f:\n",
    "#         pkl.dump([X, X_f, y, vocab_length, vocabulary], f)\n",
    "\n",
    "with open(\"training_data.pkl\", 'wb') as fo:  \n",
    "    joblib.dump([X, X_f, y, vocab_length, vocabulary], fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.87665929],\n",
       "        [0.98119469],\n",
       "        [0.98119469],\n",
       "        [0.98119469]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 15\n"
     ]
    }
   ],
   "source": [
    "mapped_song, vocab_length, vocabulary = mapping_data(single_file_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISIS DE CLASES MINORITARIAS PARA REDUCIR EL NUMERO DE LABELS\n",
    "#Se analiza el vector de targets para revisar cuantos ejemplos hay de cada clase y luego eliminar los que tienen ocurrencias despreciables\n",
    "#1. Convierte el vector de label en un integer\n",
    "y_int = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Crea un diccionario con las frecuencias ocurrencias de cada clase en los labelst\n",
    "import collections\n",
    "counter = collections.Counter(y_int)\n",
    "#y_counter = sorted(counter.items(), key=lambda x: x[1], reverse= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1441 classes with less than 10 examples\n",
      "So we can reduce the classes from 1809 to 368\n"
     ]
    }
   ],
   "source": [
    "#3. Guarda una lista con todos los labels que tienen menos de 10 ocurrencias en el dataset...\n",
    "\n",
    "minority_clases = []\n",
    "for i in range(len(counter)):\n",
    "    if counter[i] <10:\n",
    "        minority_clases.append(i)\n",
    "\n",
    "print(\"There are {} classes with less than 10 examples\".format(len(minority_clases)))\n",
    "print(\"So we can reduce the classes from {0} to {1}\".format(len(counter), len(counter) - len(minority_clases) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter) - len(minority_clases) #nro de labels que quedan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "##4. Eliminar todas los ejemplso que tengan clases con <10, que son 1441. Eso me deja 368 clases en vez de 1800...\n",
    "\n",
    "def delete_examples(X, X_f, y, minority_clases):\n",
    "    for i in range(len(minority_clases)):\n",
    "        X = np.delete(X, r[i], 0)\n",
    "        X_f = np.delete(X_f, r[i], 0)\n",
    "        y = np.delete(y, r[i], 0)\n",
    "    print(\"New shape of X data:\", X.shape)\n",
    "    print(\"New shape of y data:\", y.shape)\n",
    "    return X, X_f, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_f, y = delete_examples(X, X_f, y, minority_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y, axis = 1)\n",
    "\n",
    "for target in y_test:\n",
    "    if target in minority_clases:\n",
    "        print(\"yes\")\n",
    "    # if np.argmax(y_example, axis=0) in minority_clases:\n",
    "    #     y = np.delete(y, y_example, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_x = np.array([[0,1,0,0,0], [0,0,0,0,1], [1,0,0,0,0], [0,1,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_x, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57b02ff9a302b95782348334056a44907a346205e7822acab302370af2a72fa7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
