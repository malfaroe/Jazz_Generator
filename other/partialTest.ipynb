{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"b3DCjTbj2K37","executionInfo":{"status":"ok","timestamp":1646747564715,"user_tz":180,"elapsed":9411,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}}},"outputs":[],"source":["\"\"\"Building different modules for study and test their operation\"\"\"\n","\n","from re import S\n","import music21 as m21\n","import pandas as pd\n","import numpy as np\n","import os\n","import keras\n","#from keras.utils import to_categorical\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","#For training unit\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Activation\n","from keras.layers import BatchNormalization as BatchNorm\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","from keras.models import load_model\n","\n","\n","import json\n","import glob\n","import pickle as pkl\n","\n","import logging\n","\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) #for avoiding annoying tf warnings\n","\n","\n","##Data sources\n","#DATA_PATH = \"/Users/mauricioalfaro/Documents/mae_code/Bach/data/Jazz\"\n","SAVE_DIR = \"/Users/mauricioalfaro/Documents/mae_code/Bach/data/Jazz/encoded_dataset\"\n","#50 SONGS TEST PATH\n","DATA_PATH = \"/content/drive/MyDrive/maeGenerator22/Jazz\"\n","FILE_NAME = \"ArtPepper_Desafinado_FINAL.mid\"\n","MAPPING_JSON_NAME = \"mapping_modular.json\"\n","SEQUENCE_LENGTH = 100\n","\n","#Load a midi song into a m21 list of elements\n","\n","def multiple_song_extractor(data_path):\n","    \"\"\"Extract all the  midi  files from a folder\n","    and save them in a single m21 object\n","    args: \n","    data_path: songs path \n","    output: all_song(list): list with all the songs stacked together\"\"\"\n","\n","     #lista donde se append todos los temas\n","    all_songs = [] #lista preliminar donde se guardan todas las leidas\n","    #Read the midi song from the data folder\n","    with_chords = 0\n","    for path, subdirs, files in os.walk(data_path):\n","        for i, file in enumerate(files):\n","            #notes = []\n","            notes = []\n","            try:\n","                if file[-3:] == \"mid\" or file[-4:] == \"midi\":\n","                    midi = m21.converter.parse(os.path.join(path, file)) #parsing...crea un objeto stream.Score\n","                    #Transpose the song to Cmajor/Aminor key\n","                    midi = transpose_song(midi)\n","                    notes_to_parse = None\n","                    parts = m21.instrument.partitionByInstrument(midi) #extracts the parts\n","                    if parts: #If more than one part recorra solo la parte 0\n","                        notes_to_parse = parts.parts[0].recurse() #recurse: recorre solo la parte 0\n","                    else:\n","                        notes_to_parse = midi.flat.notes #extrae todas las notas\n","\n","                    for element in notes_to_parse:\n","                        if isinstance(element, m21.note.Note):\n","                            notes.append(str(element.pitch))\n","\n","                        elif isinstance(element, m21.chord.Chord):\n","                            with_chords +=1\n","                            continue\n","                            #notes.append(\".\".join(str(n) for n in\n","                            #element.normalOrder)) #normalOrder: distancia de la tonica en semitonos\n","                            \n","                        # elif isinstance(element, m21.note.Rest):\n","                        #     notes.append(\"r\")\n","                           \n","\n","\n","                    #all_songs.append(notes[0])\n","                    all_songs = notes + all_songs\n","            except:\n","                print(\"Failed loading the {} song\".format(i))\n","\n","    print(\"{} songs successfully loaded and converted to m21 stream objects\".format(len(all_songs)))\n","\n","    print(\"All_songs length :\", len(all_songs))\n","    print(\"Songs with chords:\", with_chords)\n","    #print(\"All_songs with 0:\", all_songs[0])\n","    #Return the list#\n","    return all_songs\n","\n","def songs_has_no_chords(song):\n","    \"\"\"Returns a boolean True indicating if song has no chords\"\"\"\n","    for element in song.flat.notesAndRests:\n","        if isinstance(element, m21.chord.Chord):\n","            return False\n","    #Returns False by default\n","    return True\n","\n","\n","def song_extractor():\n","    \"\"\"Extract all the elements from a midi and save them in a list\n","    args: \n","    songs: midi song\n","    output: notes(list)\"\"\"\n","\n","    notes = [] #lista donde se append los elementos\n","\n","    #Read the midi song from the data folder\n","    midi = m21.converter.parse(os.path.join(DATA_PATH, FILE_NAME))\n","    #Transpose the song to Cmajor/Aminor key\n","    midi = transpose_song(midi)\n","    #Extracts the song parts and check if song has more than one part\n","    notes_to_parse = None\n","    parts = m21.instrument.partitionByInstrument(midi) #extracts the parts\n","\n","    if parts: #If more than one part recorra solo la parte 0\n","        notes_to_parse = parts.parts[0].recurse() #recurse: recorre toda una parte\n","    else:\n","        notes_to_parse = midi.flat.notes #extrae todas las notas\n","\n","    #Extract elements (notes/chords/rests)\n","    for element in notes_to_parse:\n","        if isinstance(element, m21.note.Note):\n","            notes.append(str(element.pitch))\n","\n","        elif isinstance(element, m21.chord.Chord):\n","            notes.append(\".\".join(str(n) for n in\n","            element.normalOrder)) #normalOrder: distancia de la tonica en semitonos\n","\n","        elif isinstance(element, m21.note.Rest):\n","            notes.append(\"r\")\n","\n","    #Return the list\n","    return notes\n","\n","def transpose_song(song):\n","    \"\"\"Transpose the song to Cmajor/Aminor\n","    arg: song as ms21 object\n","    return: song transposed\"\"\"\n","    #Get the original key of the song\n","    parts = song.getElementsByClass(m21.stream.Part) #Extrae todas las partes de la canción (violin, viola, etc)\n","    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure) #Extrae los elementos de la parte0 como referencia\n","    \n","    try: \n","        key = measures_part0[0][4] ##tomo la primera parte de measures0 y extraigo de esa lista el elemento 4 que es key\n","\n","    except:\n","        key = song.analyze(\"key\") #si no resulta de esa forma que intente este metodo\n","\n","    #If we cant get the key by the previous method because is not in the song, estimate it\n","    if not isinstance(key, m21.key.Key): #if the song doesnt hace any key stored\n","        key = song.analyze(\"key\") #estimate it...\n","\n","    #Calculate the interval or distance to transpose\n","    #si esta en tono mayor calcula intervalo con A minor\n","    #print(\"The song is originilally in the key of {}\".format(key))\n","    if key.mode == \"minor\":\n","        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\")) #key.tonic da el tono en que está\n","\n","    elif key.mode == \"major\":\n","        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\")) #key.tonic da el tono en que está\n","\n","    #Transpose the song\n","\n","    transposed_song = song.transpose(interval)\n","\n","    #print(\"The song has been transposed to the key of {}\".format(transposed_song.analyze(\"key\")))\n","\n","    return transposed_song\n","\n","#Create a mapping function for mapping to integer-based numerical data \n","def mapping_data(song):\n","    \"\"\"Mapping all the elements of song to integers and\n","    saves the mappings dictionary\n","    arg:\n","    input (list): song encoded with the initial form (B4,r, F)\n","    output (list): mapped_song, list with song mapped to integers\"\"\"\n","    #obtener vocabulario los elementos unicos\n","    vocabulary = list(set(song))\n","    vocab_length = len(vocabulary)\n","    print(\"vocab length:\", vocab_length)\n","    #crear un diccionario {elemento: numero}\n","    mapping_dict = {}\n","    for i, element in enumerate(vocabulary):\n","        mapping_dict[element] = i\n","\n","    #Save mapping dict\n","    with open(\"mapping_modular.json\", \"w\") as fp:\n","        json.dump(mapping_dict, fp, indent = 4)\n","\n","    #mapear la cancion\n","    mapped_song = []\n","    for element in song:\n","        mapped_song.append(mapping_dict[element])\n","    #return cancion mapeada\n","    return mapped_song, vocab_length\n","\n","\n","\n","def create_data_sequences(mapped_song):\n","    \"\"\" Creates the training data taking the sequence\n","    and creating sequences of 100 elements as input\n","    and the next element as the targets, moving in a window\n","    of 1 step. Also shapes the input data to the format\n","    demanded by the LSTM: (len_dataset, SEQUENCE_LENGTH,1)\n","    args: \n","    inputs:mapped song: list of elements mapped into integers\n","    returns: \n","    - input data before scaling and reshaping (list)\n","    - input_data_final: scaled and reshaped data ready for training (array)\n","    - target data\"\"\"\n","\n","    SEQUENCE_LENGTH = 100 #largo de cada secuencia\n","    NUM_SEQUENCES = len(mapped_song) - SEQUENCE_LENGTH #total secuencias\n","\n","    input_data = []\n","    targets = []\n","    #Creating the sequences...\n","    for i in range(0, NUM_SEQUENCES, 1):\n","        input_data.append(mapped_song[i: i + SEQUENCE_LENGTH])\n","        targets.append(mapped_song[i + SEQUENCE_LENGTH])\n","\n","    print(\"Training data created\")\n","    print(\"Dataset size:\", len(input_data))\n","    #input_data = np.array(input_data) #input data before scaling\n","    targets = np.array(targets)\n","    #Normalize input data\n","    scaler = MinMaxScaler()\n","    input_data_scaled = scaler.fit_transform(input_data)\n","    \n","    #Reshape the input into a format compatible with LSTM layers...\n","    input_data_final = np.reshape(input_data_scaled, ((len(input_data_scaled), SEQUENCE_LENGTH,1)))\n","    \n","    #input_data = input_data / len(set(mapped_song))\n","\n","    #One hot encode the output\n","    targets = keras.utils.to_categorical(targets)\n","\n","    return input_data , input_data_final, targets\n","\n","\n","\n","\n","#####TRAINING UNIT\n","OUTPUT_UNITS = None #to be obtained as vocab_size variable from generate_training_sequences\n","NUM_UNITS = [256] #Hidden layer units\n","LOSS = \"sparse_categorical_crossentropy\"\n","LEARNING_RATE = 0.001\n","EPOCHS = 3\n","BATCH_SIZE = 128\n","SAVED_MODEL_NAME = \"model_modular.h5\"\n","\n","\n","\n","def train_model(model, inputs, targets, model_name = SAVED_MODEL_NAME,\n"," batch_size = BATCH_SIZE, epochs = EPOCHS):\n","    \"\"\"Train and save model\"\"\"\n","    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n","    checkpoint = ModelCheckpoint(\n","        filepath,\n","        monitor='loss',\n","        verbose=0,\n","        save_best_only=True,\n","        mode='min'\n","    )\n","    callbacks_list = [checkpoint]\n","   \n","    model.fit(inputs, targets,\n"," batch_size = BATCH_SIZE, epochs = EPOCHS, callbacks= callbacks_list)\n","\n","    #Save the model\n","    model.save(model_name)\n","    print(\"Training complete!\")\n","\n","    return model\n","\n","def build_the_model(inputs, vocab_size):\n","    \"\"\"Create the architecture of the network\"\"\"\n","    model = Sequential()\n","    model.add(LSTM(512, \n","    input_shape = (inputs.shape[1], inputs.shape[2]),\n","    recurrent_dropout= 0.3,\n","    return_sequences= True))\n","\n","    model.add(LSTM(512,recurrent_dropout= 0.3, return_sequences= True))\n","    model.add(LSTM(512))\n","    model.add(BatchNorm())\n","    model.add(Dropout(0.3))\n","    model.add(Dense(256))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNorm())\n","    model.add(Dropout(0.3))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation(\"softmax\"))\n","    \n","    model.compile(loss =\"categorical_crossentropy\", optimizer = \"rmsprop\")\n","    #model.summary()\n","    return model\n","\n","\n","##Generating music...\n","\n","def generate_notes(inputs_before_scaling, model_path,element_names,  vocab_size, temperature):\n","    \"\"\"Takes a random sequence from the inputs \n","    and predicts a sequence of 500 notes using the model\n","    args:\n","    model: trained model\n","    inputs_before_scaling: array of input training data BEFORE the scaling and reshaping (list)\n","    element_names: elements of the dictionary (notes and rests)\n","    vocab_size: integer, size of the vocabulary\n","    temperature (0-1): the higher the random the choice\n","    \n","    output:\n","    prediction_output: sequence of 500 notes predicted by the model\"\"\"\n","    #Loads the model\n","    model = keras.models.load_model(model_path)\n","    #Choose a random training example from input\n","    start = np.random.randint(0, len(inputs_before_scaling) -1 ) #random example index\n","    input_sequence = inputs_before_scaling[start]  #input vector randomly chosen\n","    predicted_sequence = []\n","    #inverse dictionary {number: element, 3:\"B4\"}\n","    int_to_note = dict((i, element) for i, element in enumerate(element_names)) \n","\n","    #Predicts a sequence of 500 notes using the model\n","    for i in range(500):\n","        #Prepare sequence for predict\n","        #Scaling the sequence\n","        scaler = MinMaxScaler()\n","        prepared_sequence = scaler.fit_transform(np.array(input_sequence).reshape(-1, 1))\n","        #Reshaping\n","        prepared_sequence = np.reshape(prepared_sequence, (1, len(prepared_sequence),1))\n","       \n","        prediction = model.predict(prepared_sequence, verbose = 0)[0]\n","        index = sample_with_temperature(prediction, temperature) #digito using temperature\n","\n","        #index = np.argmax(prediction) #digito predicha con mayor prob\n","        prediction_to_note = int_to_note[index] #entrega la nota correspondiente al digito que predijo\n","        predicted_sequence.append(prediction_to_note)\n","        input_sequence.append(index) #adds the predicted note to the input sequence\n","        input_sequence = input_sequence[1:len(input_sequence)] #se corre un elemento a la derecha\n","    print(\"Predicted sequence:\", predicted_sequence)\n","    return predicted_sequence\n","\n","def sample_with_temperature(probabilities, temperature):\n","        \"\"\"Using temperature gives the chance of picking a random note different from the obvious\n","        which is the one that the model assigns the highest prob. If temperature is zero, we pick\n","        that one, but with higher values appears a random choice.\n","        \n","        By dividing log(probabilities_vector) /temperature, if temperature is closer to 1 this\n","        value will be smaller, hence the softmax of this will be softened (with more similar values)\n","        On the contrary, with temp closer to zero this difference will accentuate \n","        args:\n","        probabilities (ndarray): array containing the probability of each possible outcome\n","        temperature: float in interval [0,1]. Number closer to 0 makes the model more deterministic,\n","        A number closer to 1  makes the generation more impredictable\n","            \n","            return: selected output symbol \"\"\"\n","        predictions = np.log(probabilities) / temperature\n","        probabilities = np.exp(predictions) / np.sum(np.exp(predictions)) #Softmax vector\n","\n","        choices = range(len(probabilities)) #[0,1,2,3,4,5,....] posible outcomes (espacio muestral)\n","        index = np.random.choice(choices, p = probabilities)\n","        return index\n","\n","#Convert to midi\n","\n","def convert_to_midi(predicted_sequence):\n","    \"\"\"Takes the predicted sequence and translate bit by bit to a\n","    midi sequence\n","    args:\n","    input: predicted_sequence(list): song in B4, 3.5, \"r\", format\n","    output: midi_stream: stream or list with translated elements\"\"\"\n","\n","    offset = 0 #offset: location of the element in the sequence\n","    output_notes = []\n","\n","    for element in predicted_sequence:\n","    \n","        #if is a chord\n","        if (\".\" in element) or element.isdigit(): # Si tiene la forma 3.5\n","            element = element.split(\".\") #quito el .\n","            chord_notes = []\n","            for item in element:\n","                new_note = m21.note.Note(int(item))\n","                new_note.storedInstrument = m21.instrument.Piano()\n","                chord_notes.append(new_note)\n","            new_chord = m21.chord.Chord(chord_notes)\n","            new_chord.offset = offset\n","            output_notes.append(new_chord)\n","            \n","        #if it is a rest\n","        elif element == \"r\":\n","            note = m21.note.Rest()\n","            note.offset = offset\n","            output_notes.append(note)\n","\n","\n","        #If it is a note\n","        else:\n","            note = m21.note.Note(element)\n","            m21.note.storedInstrument = m21.instrument.Piano()\n","            note.offset = offset\n","            output_notes.append(note)\n","\n","\n","        #increase the offset \n","        offset += 1\n","    #Convert to midi and save\n","    midi_stream = m21.stream.Stream(output_notes)\n","    midi_stream.write(\"midi\", fp = \"midiMae.mid\")\n","\n","#Test \n","\n","# if __name__ == \"__main__\":\n","#     notes = multiple_song_extractor(DATA_PATH)\n","#     #notes = song_extractor()\n","#     print(\"List length:\", len(notes))\n","#     print(notes[:20])\n","#     mapped_song, vocab_length = mapping_data(notes)\n","#     print(\"Number of target classes :\", len(set(mapped_song)))\n","#     X, X_f, y = create_data_sequences(mapped_song)\n","\n","#     with open(\"training_data.pkl\", \"wb\") as f:\n","#         pkl.dump([X, X_f, y], f)\n","#     # model = build_the_model(X_f, vocab_length)\n","#     # model = train_model(model, inputs = X_f, targets = y, model_name = SAVED_MODEL_NAME,batch_size = BATCH_SIZE, epochs = EPOCHS)\n","#     #prediction = generate_notes(X, SAVED_MODEL_NAME, list(set(notes)), vocab_length, 0.9)\n","#     #convert_to_midi(prediction)\n","#     print(\"Done!\")\n","\n","\n","##TEST FOR PARTIAL TRAINING\n","\n","\n","#data_path = \"C:\\Users\\malfaro\\Desktop\\maeGenerator22\\training_data.pkl\"\n","\n","\n","def data_load(data_path):\n","    \"\"\"Loads the training data and parameters using pickle\n","args: data_path: location of the pkl file containing the data\n","called training_data.pkl and unpacks all the data\n","\"\"\"\n","    with open(data_path, \"rb\") as f:\n","        X, X_f, y, vocab_length = pkl.load(f)\n","    print(\"Loaded data summary:\")\n","    print(\"=======================\")\n","    print(\"Number of training examples:\", len(X))\n","    print(\"Processed input data size:\", X_f.shape)\n","    print(\"Target data size:\", y.shape)\n","    print(\"Nr of target classes:\", vocab_length)\n","    return X, X_f, y, vocab_length\n","\n","if __name__ == \"__main__\":\n","    pass\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHewPy3G2N08","executionInfo":{"status":"ok","timestamp":1646747597251,"user_tz":180,"elapsed":23162,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}},"outputId":"5e5a8e3a-ea16-44a4-af7e-99ed8b4542fa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["###TESTING LATEST\n","DATA_PATH = \"/content/drive/MyDrive/maeGenerator22/training_data.pkl\"\n","TRAINED_MODEL = \"/content/drive/MyDrive/maeGenerator22/weights-FINAL.hdf5\"\n","#Load data\n","X, X_f, y, vocab_length = data_load(DATA_PATH)\n","#Load model\n","\n","#Predict\n","#prediction = generate_notes(X, FINAL_MODEL, list(set(notes)), vocab_length, 0.9)\n","#Convert to midi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ss40430fznBu","executionInfo":{"status":"ok","timestamp":1646752751403,"user_tz":180,"elapsed":6584,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}},"outputId":"170e834d-7da2-469c-d8da-0216fd26d682"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded data summary:\n","=======================\n","Number of training examples: 209471\n","Processed input data size: (209471, 100, 1)\n","Target data size: (209471, 445)\n","Nr of target classes: 445\n"]}]},{"cell_type":"code","source":["X[:3]"],"metadata":{"id":"zYI9mw4AHVRa","executionInfo":{"status":"ok","timestamp":1646752787507,"user_tz":180,"elapsed":227,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}},"outputId":"c46d8289-a231-4790-e41b-5cce22d515dd","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[116,\n","  250,\n","  6,\n","  348,\n","  405,\n","  405,\n","  348,\n","  361,\n","  6,\n","  6,\n","  348,\n","  361,\n","  250,\n","  250,\n","  116,\n","  250,\n","  116,\n","  209,\n","  108,\n","  108,\n","  441,\n","  116,\n","  116,\n","  441,\n","  116,\n","  209,\n","  81,\n","  144,\n","  144,\n","  144,\n","  81,\n","  209,\n","  209,\n","  441,\n","  108,\n","  203,\n","  144,\n","  203,\n","  144,\n","  108,\n","  441,\n","  361,\n","  116,\n","  305,\n","  108,\n","  188,\n","  81,\n","  218,\n","  441,\n","  441,\n","  116,\n","  6,\n","  116,\n","  6,\n","  348,\n","  394,\n","  405,\n","  394,\n","  348,\n","  361,\n","  6,\n","  116,\n","  108,\n","  441,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  188,\n","  188,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  188,\n","  441,\n","  116,\n","  375,\n","  188,\n","  441,\n","  116,\n","  188,\n","  441,\n","  348,\n","  6,\n","  348,\n","  348,\n","  6,\n","  394,\n","  6,\n","  116,\n","  441,\n","  108,\n","  188],\n"," [250,\n","  6,\n","  348,\n","  405,\n","  405,\n","  348,\n","  361,\n","  6,\n","  6,\n","  348,\n","  361,\n","  250,\n","  250,\n","  116,\n","  250,\n","  116,\n","  209,\n","  108,\n","  108,\n","  441,\n","  116,\n","  116,\n","  441,\n","  116,\n","  209,\n","  81,\n","  144,\n","  144,\n","  144,\n","  81,\n","  209,\n","  209,\n","  441,\n","  108,\n","  203,\n","  144,\n","  203,\n","  144,\n","  108,\n","  441,\n","  361,\n","  116,\n","  305,\n","  108,\n","  188,\n","  81,\n","  218,\n","  441,\n","  441,\n","  116,\n","  6,\n","  116,\n","  6,\n","  348,\n","  394,\n","  405,\n","  394,\n","  348,\n","  361,\n","  6,\n","  116,\n","  108,\n","  441,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  188,\n","  188,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  188,\n","  441,\n","  116,\n","  375,\n","  188,\n","  441,\n","  116,\n","  188,\n","  441,\n","  348,\n","  6,\n","  348,\n","  348,\n","  6,\n","  394,\n","  6,\n","  116,\n","  441,\n","  108,\n","  188,\n","  81],\n"," [6,\n","  348,\n","  405,\n","  405,\n","  348,\n","  361,\n","  6,\n","  6,\n","  348,\n","  361,\n","  250,\n","  250,\n","  116,\n","  250,\n","  116,\n","  209,\n","  108,\n","  108,\n","  441,\n","  116,\n","  116,\n","  441,\n","  116,\n","  209,\n","  81,\n","  144,\n","  144,\n","  144,\n","  81,\n","  209,\n","  209,\n","  441,\n","  108,\n","  203,\n","  144,\n","  203,\n","  144,\n","  108,\n","  441,\n","  361,\n","  116,\n","  305,\n","  108,\n","  188,\n","  81,\n","  218,\n","  441,\n","  441,\n","  116,\n","  6,\n","  116,\n","  6,\n","  348,\n","  394,\n","  405,\n","  394,\n","  348,\n","  361,\n","  6,\n","  116,\n","  108,\n","  441,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  108,\n","  188,\n","  188,\n","  441,\n","  116,\n","  108,\n","  441,\n","  116,\n","  188,\n","  441,\n","  116,\n","  375,\n","  188,\n","  441,\n","  116,\n","  188,\n","  441,\n","  348,\n","  6,\n","  348,\n","  348,\n","  6,\n","  394,\n","  6,\n","  116,\n","  441,\n","  108,\n","  188,\n","  81,\n","  203]]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wx9UwZ0C2K4C","executionInfo":{"status":"ok","timestamp":1646665543489,"user_tz":180,"elapsed":616571,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}},"outputId":"1e8aefbd-807c-4a24-cc46-caba84a9f4d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Failed loading the 76 song\n","Failed loading the 97 song\n","Failed loading the 133 song\n","206718 songs successfully loaded and converted to m21 stream objects\n","All_songs length : 206718\n","Songs with chords: 272\n","vocab length: 81\n","List length: 206718\n","['B-3', 'C#4', 'F4', 'G#4', 'G4', 'F4', 'E-4', 'C4', 'G#3', 'B3', 'C#4', 'E-4', 'F#4', 'E4', 'B3', 'G#3', 'G#3', 'F3', 'E3', 'D3']\n","Training data created\n","Dataset size: 206618\n","Done!\n"]}],"source":["notes = multiple_song_extractor(DATA_PATH)\n","mapped_song, vocab_length = mapping_data(notes)\n","#notes = song_extractor()\n","print(\"List length:\", len(notes))\n","print(notes[:20])\n","X, X_f, y = create_data_sequences(mapped_song)\n","#new_model = load_model(\"weights-VIERNES.hdf5\")\n","new_model = \"weights-LUNES7-bigger.hdf5\"\n","#prediction = generate_notes(X, new_model, list(set(notes)), vocab_length, 0.9)\n","#convert_to_midi(prediction)\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"pknXc2_Y2K4D","executionInfo":{"status":"error","timestamp":1646665629759,"user_tz":180,"elapsed":2917,"user":{"displayName":"Mauricio Alfaro","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16047939764221462828"}},"outputId":"fb90caed-6dea-4eab-a159-04b22bea142a"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ce27dee0e71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Checking the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/maeGenerator22/weights-LUNES7-bigger.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconvert_to_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-e5f0c76cff1a>\u001b[0m in \u001b[0;36mgenerate_notes\u001b[0;34m(inputs_before_scaling, model_path, element_names, vocab_size, temperature)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m#index = np.argmax(prediction) #digito predicha con mayor prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mprediction_to_note\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#entrega la nota correspondiente al digito que predijo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mpredicted_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_to_note\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0minput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#adds the predicted note to the input sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 405"]}],"source":["#Checking the trained model\n","new_model = \"/content/drive/MyDrive/maeGenerator22/weights-LUNES7-bigger.hdf5\"\n","prediction = generate_notes(X, new_model, list(set(notes)), vocab_length, 0.9)\n","convert_to_midi(prediction)\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wK4AaXAj2K4E","outputId":"a751a196-2542-4e55-d070-8a00ec131aa8"},"outputs":[{"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"]}],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WV8XI7l2K4E"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"partialTest.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}